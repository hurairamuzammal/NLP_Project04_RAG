{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13900478,"sourceType":"datasetVersion","datasetId":8856101}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up Env","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport numpy as np\nfrom typing import List, Dict\nfrom sentence_transformers import SentenceTransformer, util","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:41:39.553624Z","iopub.execute_input":"2025-11-30T20:41:39.554147Z","iopub.status.idle":"2025-11-30T20:42:15.481321Z","shell.execute_reply.started":"2025-11-30T20:41:39.554123Z","shell.execute_reply":"2025-11-30T20:42:15.480573Z"}},"outputs":[{"name":"stderr","text":"2025-11-30 20:41:53.460761: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764535313.665070      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764535313.725985      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers accelerate huggingface-hub sentence-transformers faiss-cpu streamlit python-dotenv --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:50:53.840079Z","iopub.execute_input":"2025-11-30T20:50:53.840931Z","iopub.status.idle":"2025-11-30T20:50:58.494269Z","shell.execute_reply.started":"2025-11-30T20:50:53.840900Z","shell.execute_reply":"2025-11-30T20:50:58.493319Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# using this lightweight sentence transformer\nimport faiss\nMODEL_NAME = 'all-MiniLM-L6-v2'\nTOP_K=3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T20:52:26.313753Z","iopub.execute_input":"2025-11-30T20:52:26.314575Z","iopub.status.idle":"2025-11-30T20:52:26.318374Z","shell.execute_reply.started":"2025-11-30T20:52:26.314534Z","shell.execute_reply":"2025-11-30T20:52:26.317701Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# RAG Pipeline","metadata":{}},{"cell_type":"code","source":"def load_data(file_path):\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)\n\nkb_items = load_data(\"/kaggle/input/medicaldataset-nlp-a04/combined_rag_data.json\")\n\nmodel = SentenceTransformer(MODEL_NAME,device='cuda')\n\ndef generate_embeddings(model, items):\n    texts = []\n    for item in items:\n        if 'medicalKB' in item:\n            texts.append(item['medicalKB'])\n        elif 'patient_case' in item:\n            texts.append(\" \".join(item['patient_case']['inputs'].values()))\n    embeddings = model.encode(texts, convert_to_tensor=True, device=\"cuda\")\n    return embeddings, texts\n\nkb_embeddings, kb_texts = generate_embeddings(model, kb_items)\n\ndef retrieve_top_k(query, model, index, items, k=TOP_K):\n    q_emb = model.encode([query], convert_to_tensor=True, device=\"cuda\")\n    q_emb_np = q_emb.cpu().detach().numpy().astype(\"float32\")\n    faiss.normalize_L2(q_emb_np)\n    scores, idx = index.search(q_emb_np, k)\n    return [(items[i], float(scores[0][j])) for j, i in enumerate(idx[0])]\n\ndef build_faiss_index(embeddings):\n    embeddings_np = embeddings.cpu().detach().numpy().astype(\"float32\")\n    faiss.normalize_L2(embeddings_np) \n    d = embeddings_np.shape[1]\n    index = faiss.IndexFlatIP(d)\n    index.add(embeddings_np)\n    return index\n\n\nfaiss_index = build_faiss_index(kb_embeddings)\nfaiss.write_index(faiss_index, \"medical_kb_index.faiss\")\n\ndef construct_prompt(patient_case, retrieved):\n    context_str = \"Relevant Information:\\n\"\n    for item, score in retrieved:\n        if 'medicalKB' in item:\n            context_str += f\"- {item['medicalKB'][:500]}... (Relevance: {score:.2f})\\n\"\n        elif 'patient_case' in item:\n            patient_text = \" \".join(item['patient_case']['inputs'].values())\n            context_str += f\"- {patient_text[:500]}... (Relevance: {score:.2f})\\n\"\n\n    prompt = f\"\"\"\nYou are an expert medical diagnostician.\nUse the provided medical knowledge and patient cases to explain the query.\n\n{context_str}\n\nPatient Query:\n{patient_case['input_text']}\n\nGive reasoning and final answer.\n\"\"\"\n    return prompt\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:04:09.621836Z","iopub.execute_input":"2025-11-30T21:04:09.622666Z","iopub.status.idle":"2025-11-30T21:04:12.008279Z","shell.execute_reply.started":"2025-11-30T21:04:09.622637Z","shell.execute_reply":"2025-11-30T21:04:12.007341Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Preparing HuggingFace LLM","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForCausalLM\nimport torch\nLLM_Model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\ntokenizer=AutoTokenizer.from_pretrained(LLM_Model,use_fast=False)\nllm=AutoModelForCausalLM.from_pretrained(LLM_Model,torch_dtype=torch.float16,device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:04:12.009664Z","iopub.execute_input":"2025-11-30T21:04:12.010241Z","iopub.status.idle":"2025-11-30T21:04:41.932663Z","shell.execute_reply.started":"2025-11-30T21:04:12.010220Z","shell.execute_reply":"2025-11-30T21:04:41.931998Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9abe36ca254ad7a1c91505f371e000"}},"metadata":{}},{"name":"stderr","text":"WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"def llm_generate(prompt, max_new_tokens=256):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n    output = llm.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:04:41.933401Z","iopub.execute_input":"2025-11-30T21:04:41.933670Z","iopub.status.idle":"2025-11-30T21:04:41.938075Z","shell.execute_reply.started":"2025-11-30T21:04:41.933640Z","shell.execute_reply":"2025-11-30T21:04:41.937382Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def run_rag(patient_case, kb_items, index):\n    retrieved = retrieve_top_k(patient_case[\"input_text\"], model, index, kb_items)\n    prompt = construct_prompt(patient_case, retrieved)\n    answer = llm_generate(prompt)\n    return answer, retrieved, prompt\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:04:41.939845Z","iopub.execute_input":"2025-11-30T21:04:41.940070Z","iopub.status.idle":"2025-11-30T21:04:41.953812Z","shell.execute_reply.started":"2025-11-30T21:04:41.940054Z","shell.execute_reply":"2025-11-30T21:04:41.953095Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Model Inference","metadata":{}},{"cell_type":"code","source":"patient_case = {\n    \"input_text\": \"A 65-year-old male with aggressive behavior and recent falls...\"\n}\n\nfaiss_index = faiss.read_index(\"medical_kb_index.faiss\")\nanswer, retrieved, prompt = run_rag(patient_case, kb_items, faiss_index)\nprint(answer)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:04:41.954589Z","iopub.execute_input":"2025-11-30T21:04:41.954828Z","iopub.status.idle":"2025-11-30T21:05:40.281246Z","shell.execute_reply.started":"2025-11-30T21:04:41.954812Z","shell.execute_reply":"2025-11-30T21:05:40.280564Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nYou are an expert medical diagnostician.\nUse the provided medical knowledge and patient cases to explain the query.\n\nRelevant Information:\n- Dementia with aggresive behavior Man with CAD, prostate cancer, meningioma, and gastritis, and two recent ER visits for aggressive behavior, sent from his nursing facility for safety evaluation after striking another resident in the face at the facility. \n\nThis patient has been living in the Memory Unit about the past year. Seen in our ED on for similar presentation. On his last visit, after one day in ED observation was willing to take the patient back if under good behavioral control, which he... (Relevance: 0.44)\n- Cardiac ArrestChest Pain He is a 58 year old gentleman with a history of significant alcohol use and heavy smoking with a recent neurologic decline who presents to the CCU after witnessed cardiac arrest. \n\nHe has had a steep neurologic decline over the past two months. He has been a lifelong heavy drinker and smoker, but he's been drinking far more than usual and at atypical times of day. He's also had erratic behavior including spending all his time naked, being incontinent of urine and sometim... (Relevance: 0.41)\n- Hypotension He is a 31 M with complicated history of undiagnosed myopathy who has been recently evaluated for numerous falls. He was seen by his PCP today for routine and noted to have orthostatic hypotension with supine BP of 110/50 and standing of 60/20. Patient was sent to the ER.  \n\nOf note, he had 3 \"falls\" in which he says his legs dropped out from under him and he fell. He had some blackening of his vision during these events but no associated chest pain, palpitations or shortness of brea... (Relevance: 0.41)\n\n\nPatient Query:\nA 65-year-old male with aggressive behavior and recent falls...\n\nGive reasoning and final answer.\n</think>\n\nThe patient is a 65-year-old male with aggressive behavior and recent falls. Based on the provided information, the most relevant case is the 58-year-old gentleman with a history of significant alcohol use and heavy smoking who presented to the CCU after a cardiac arrest. He had a steep neurologic decline over the past two months, was a lifelong heavy drinker and smoker, and exhibited erratic behavior. \n\nThe patient's aggressive behavior and falls could be related to his neurologic decline, heavy alcohol use, and smoking. These factors could contribute to his aggressive behavior and increase the risk of falls. Therefore, the most relevant case is the 58-year-old gentleman with a history of significant alcohol use and heavy smoking who presented to the CCU after a cardiac arrest.\n\n**Answer:** The most relevant case is the 58-year-old gentleman with a history of significant alcohol use and heavy smoking who presented to the CCU after a cardiac arrest.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Using API Models","metadata":{}},{"cell_type":"code","source":"!pip install google-generativeai python-dotenv --quiet\n\nimport os\nfrom dotenv import load_dotenv\nimport google.generativeai as genai\n\n# Get API key\napi_key = \"AIzaSyCVdJA9SNoTgas-fytZtPatxfn8-5IgmZ4\"\n\n\ngenai.configure(api_key=api_key)\n\n# Example prompt\nprompt = \"\"\"\nFirst explain what it diesase could be then give all the reasons\nExplain the symptoms of a 60-year-old male with sudden chest pain radiating to the back.\nUse headings or bullet points where needed.\nGive response in plain text without * Behave like medical assistant\n\"\"\"\n\n# Generate response\nmodel = genai.GenerativeModel(\"gemini-2.0-flash\")\nresponse = model.generate_content(prompt)\n\nprint(response.text)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T21:08:19.463740Z","iopub.execute_input":"2025-11-30T21:08:19.464729Z","iopub.status.idle":"2025-11-30T21:08:27.595996Z","shell.execute_reply.started":"2025-11-30T21:08:19.464686Z","shell.execute_reply":"2025-11-30T21:08:27.595194Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Okay, here's a breakdown of what a 60-year-old male experiencing sudden chest pain radiating to the back could indicate, along with possible reasons and symptoms:\n\n**Possible Disease:**\n\nThe primary concern with sudden chest pain radiating to the back in a 60-year-old male is **acute aortic dissection**. This is a life-threatening condition. However, other serious possibilities include a **heart attack (acute myocardial infarction)**, and less likely, **pulmonary embolism**.\n\n**Reasons for Sudden Chest Pain Radiating to the Back:**\n\n*   **Aortic Dissection:**\n    *   A tear in the inner layer of the aorta (the body's largest artery) allows blood to surge between the layers of the aortic wall, causing them to separate (dissect).\n    *   Risk factors include: high blood pressure, genetic conditions affecting the aorta (like Marfan syndrome), pre-existing aortic aneurysm, atherosclerosis (hardening of the arteries), injury to the chest, and occasionally, during weightlifting.\n*   **Acute Myocardial Infarction (Heart Attack):**\n    *   A blockage in one or more of the coronary arteries (which supply blood to the heart muscle) deprives the heart muscle of oxygen.\n    *   Risk factors include: high cholesterol, high blood pressure, smoking, diabetes, obesity, family history of heart disease, and older age.\n*   **Pulmonary Embolism:**\n    *   A blood clot that travels to the lungs, blocking blood flow.\n    * Risk Factors: immobility, recent surgery or trauma, cancer, smoking, obesity and certain genetic conditions.\n\n**Symptoms:**\n\nThe patient may experience the following:\n\n*   **Chest Pain:**\n    *   Sudden onset, severe, and often described as tearing, ripping, or stabbing.\n    *   Located in the chest, but importantly, radiating to the back, often between the shoulder blades.\n    *   May or may not be associated with exertion.\n*   **Other Symptoms:**\n    *   Sweating (diaphoresis)\n    *   Nausea and/or vomiting\n    *   Shortness of breath (dyspnea)\n    *   Lightheadedness or dizziness, possibly fainting (syncope)\n    *   Anxiety or a sense of impending doom\n    *   Difference in blood pressure between arms (more common in aortic dissection)\n    *   Weakness or paralysis (if the dissection affects blood flow to the spinal cord or brain)\n    *   Rapid heart rate (tachycardia) or irregular heart beat.\n    *   Change in mental status\n\n**Important Considerations:**\n\n*   This combination of symptoms requires immediate medical attention.\n*   Time is critical. Call emergency services (911) immediately. Do not attempt to drive the patient to the hospital.\n*   Inform the emergency responders about the symptoms, especially the chest pain radiating to the back.\n* The information provided here is not a substitute for professional medical advice.\n\n","output_type":"stream"}],"execution_count":31}]}