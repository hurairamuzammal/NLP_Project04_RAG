{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First cleaning our medicalknowlege base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import re\n",
    "\n",
    "# # Define paths\n",
    "# base_path = os.getcwd()\n",
    "# kb_folder_path = os.path.join(base_path, \"medicalKnowledgeBase\", \"Diagnosis_flowchart\")\n",
    "# patient_cases_folder = os.path.join(base_path, \"Finished\")\n",
    "# output_file = os.path.join(base_path, \"combined_rag_data.json\")\n",
    "\n",
    "# print(f\"Knowledge Base Path: {kb_folder_path}\")\n",
    "# print(f\"Patient Cases Path: {patient_cases_folder}\")\n",
    "\n",
    "# def clean_text(text):\n",
    "#     if not isinstance(text, str):\n",
    "#         return text\n",
    "#     cleaned = re.sub(r'\\s*___\\s*', ' ', text)\n",
    "\n",
    "#     cleaned = re.sub(r' +', ' ', cleaned\n",
    "#     cleaned = re.sub(r' +([,.:;])', r'\\1', cleaned)\n",
    "#     return cleaned.strip()\n",
    "\n",
    "# # Counter for generating unique IDs\n",
    "# kb_id_counter = 0\n",
    "\n",
    "# def Convertorfunction(data, parent_key=\"\"):\n",
    "#     global kb_id_counter\n",
    "#     items = []\n",
    "#     for key, value in data.items():\n",
    "#         new_key = f\"{parent_key}/{key}\" if parent_key else key\n",
    "\n",
    "#         if isinstance(value, str):\n",
    "#             kb_id_counter += 1\n",
    "#             items.append({\n",
    "#                 \"id\": f\"KB_{kb_id_counter:04d}\",\n",
    "#                 \"medicalKB\": f\"{new_key}: {value}\"\n",
    "#             })\n",
    "#         elif isinstance(value, list):\n",
    "#             kb_id_counter += 1\n",
    "#             items.append({\n",
    "#                 \"id\": f\"KB_{kb_id_counter:04d}\",\n",
    "#                 \"medicalKB\": f\"{new_key}: []\"\n",
    "#             })\n",
    "#         elif isinstance(value, dict):\n",
    "#             items.extend(Convertorfunction(value, new_key))\n",
    "#     return items\n",
    "\n",
    "# knowledge_base_entries = []\n",
    "\n",
    "# if os.path.exists(kb_folder_path):\n",
    "#     for file_name in os.listdir(kb_folder_path):\n",
    "#         if file_name.endswith(\".json\"):\n",
    "#             file_path = os.path.join(kb_folder_path, file_name)\n",
    "#             with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 data = json.load(f)\n",
    "#             knowledge_base_entries.extend(Convertorfunction(data))\n",
    "#     print(f\"Processed {len(knowledge_base_entries)} knowledge base entries\")\n",
    "# else:\n",
    "#     print(f\"Warning: Knowledge base folder not found at {kb_folder_path}\")\n",
    "\n",
    "# def flatten_reasoning(obj, prefix=\"\"):\n",
    "#     parts = []\n",
    "#     if isinstance(obj, dict):\n",
    "#         for key, value in obj.items():\n",
    "#             new_prefix = f\"{prefix} -> {key}\" if prefix else key\n",
    "#             if isinstance(value, dict) and value:  # Non-empty dict\n",
    "#                 parts.append(flatten_reasoning(value, new_prefix))\n",
    "#             else:\n",
    "#                 parts.append(new_prefix)\n",
    "#     return \" | \".join(filter(None, parts))\n",
    "\n",
    "# def process_patient_case(file_path, file_name, disease_group, specific_disease=None):\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         try:\n",
    "#             data = json.load(f)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(f\"Error decoding JSON: {file_path}\")\n",
    "#             return None\n",
    "\n",
    "#     inputs = {}\n",
    "#     reasoning = {}\n",
    "#     for key, value in data.items():\n",
    "#         if key.lower().startswith(\"input\"):\n",
    "#             inputs[key] = value\n",
    "#         else:\n",
    "#             reasoning[key] = value\n",
    "\n",
    "#     cleaned_inputs = {}\n",
    "#     for i in range(1, 7):\n",
    "#         key = f\"input{i}\"\n",
    "#         val = None\n",
    "#         for k in inputs:\n",
    "#             if k.lower() == key:\n",
    "#                 val = inputs[k]\n",
    "#                 break\n",
    "        \n",
    "#         if not val or (isinstance(val, str) and val.strip() == \"\"):\n",
    "#             val = \"NA\"\n",
    "        \n",
    "#         if isinstance(val, str):\n",
    "#             cleaned_inputs[key] = clean_text(val.strip())\n",
    "#         else:\n",
    "#             cleaned_inputs[key] = val\n",
    "\n",
    "#     reasoning_string = flatten_reasoning(reasoning)\n",
    "#     # here i am using file name asid \n",
    "#     case_id = file_name.replace(\".json\", \"\")\n",
    "    \n",
    "#     case_entry = {\n",
    "#         \"id\": case_id,\n",
    "#         \"patient_case\": {\n",
    "#             \"disease_group\": disease_group,\n",
    "#             \"specific_disease\": specific_disease if specific_disease else \"NA\",\n",
    "#             \"reasoning\": reasoning_string,\n",
    "#             \"inputs\": cleaned_inputs\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "#     return case_entry\n",
    "\n",
    "# patient_cases_entries = []\n",
    "\n",
    "# if os.path.exists(patient_cases_folder):\n",
    "#     for root, dirs, files in os.walk(patient_cases_folder):\n",
    "#         for file in files:\n",
    "#             if file.endswith(\".json\"):\n",
    "#                 file_path = os.path.join(root, file)\n",
    "                \n",
    "#                 rel_path = os.path.relpath(root, patient_cases_folder)\n",
    "#                 path_parts = rel_path.split(os.sep)\n",
    "                \n",
    "#                 # Get disease group and specific disease from folder structure\n",
    "#                 if len(path_parts) >= 1 and path_parts[0] != \".\":\n",
    "#                     disease_group = path_parts[0]\n",
    "#                     specific_disease = path_parts[1] if len(path_parts) > 1 else None\n",
    "                    \n",
    "#                     case_data = process_patient_case(file_path, file, disease_group, specific_disease)\n",
    "#                     if case_data:\n",
    "#                         patient_cases_entries.append(case_data)\n",
    "#     print(f\"Processed {len(patient_cases_entries)} patient cases\")\n",
    "# else:\n",
    "#     print(f\"Warning: Patient cases folder not found at {patient_cases_folder}\")\n",
    "\n",
    "# # Combine knowledge base entries (upper part) with patient cases (lower part)\n",
    "# combined_data = knowledge_base_entries + patient_cases_entries\n",
    "\n",
    "# # Save the combined output\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(combined_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(f\"\\n=== Summary ===\")\n",
    "# print(f\"Total Knowledge Base entries: {len(knowledge_base_entries)} (IDs: KB_0001 to KB_{kb_id_counter:04d})\")\n",
    "# print(f\"Total Patient Cases: {len(patient_cases_entries)}\")\n",
    "# print(f\"Combined entries: {len(combined_data)}\")\n",
    "# print(f\"Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:06:26.091822Z",
     "iopub.status.busy": "2025-11-29T10:06:26.091588Z",
     "iopub.status.idle": "2025-11-29T10:06:59.560539Z",
     "shell.execute_reply": "2025-11-29T10:06:59.559930Z",
     "shell.execute_reply.started": "2025-11-29T10:06:26.091794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Muhammad Abu Huraira\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\muhammad abu huraira\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Abu Huraira\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Abu Huraira\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:06:59.562477Z",
     "iopub.status.busy": "2025-11-29T10:06:59.561903Z",
     "iopub.status.idle": "2025-11-29T10:08:09.782095Z",
     "shell.execute_reply": "2025-11-29T10:08:09.781172Z",
     "shell.execute_reply.started": "2025-11-29T10:06:59.562460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Muhammad Abu Huraira\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate huggingface-hub sentence-transformers faiss-cpu streamlit python-dotenv --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:08:09.783574Z",
     "iopub.status.busy": "2025-11-29T10:08:09.783242Z",
     "iopub.status.idle": "2025-11-29T10:08:09.787826Z",
     "shell.execute_reply": "2025-11-29T10:08:09.787177Z",
     "shell.execute_reply.started": "2025-11-29T10:08:09.783540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# using this lightweight sentence transformer\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "TOP_K=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:08:09.788859Z",
     "iopub.status.busy": "2025-11-29T10:08:09.788596Z",
     "iopub.status.idle": "2025-11-29T10:08:09.803277Z",
     "shell.execute_reply": "2025-11-29T10:08:09.802629Z",
     "shell.execute_reply.started": "2025-11-29T10:08:09.788837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    with open(file_name,\"r\",encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "    return data\n",
    "\n",
    "def generate_vector_embedding(model, kb_items):\n",
    "    print(\"Creating Vector embeddings of the json file\")\n",
    "    texts = [f\"{item.get('id','')} : {item.get('medicalKB','')}\" for item in kb_items]\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def retrieve_from_kb(model, query_text, kb_embeddings, kb_items, k=TOP_K):\n",
    "    query_emb = model.encode(query_text, convert_to_tensor=True)\n",
    "\n",
    "    cos_scores = util.cos_sim(query_emb, kb_embeddings)[0]\n",
    "    scores = cos_scores.cpu().numpy()\n",
    "\n",
    "    k = min(k, len(scores))\n",
    "    top_idx = np.argpartition(-scores, range(k))[:k]\n",
    "    top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append((\n",
    "            kb_items[int(idx)],\n",
    "            float(scores[int(idx)])\n",
    "        ))\n",
    "\n",
    "    return results\n",
    "\n",
    "def construct_prompt(patient_case, retrieved_kb):\n",
    "    context_str = \"Medical Knowledge:\\n\"\n",
    "    for item, score in retrieved_kb:\n",
    "        context_str += f\"- [{item.get('id','')}] {item.get('medicalKB','')} (Relevance: {score:.2f})\\n\"\n",
    "\n",
    "    case_str = f\"Patient Case Details:\\n{patient_case['input_text']}\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert medical diagnostician.\n",
    "Use the provided medical knowledge to explain the patient case.\n",
    "\n",
    "{context_str}\n",
    "\n",
    "{case_str}\n",
    "\n",
    "Give reasoning and final answer.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:08:09.804349Z",
     "iopub.status.busy": "2025-11-29T10:08:09.804087Z",
     "iopub.status.idle": "2025-11-29T10:09:27.185231Z",
     "shell.execute_reply": "2025-11-29T10:09:27.184595Z",
     "shell.execute_reply.started": "2025-11-29T10:08:09.804333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [04:45<00:00, 142.52s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.43s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import torch\n",
    "LLM_Model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(LLM_Model,use_fast=False)\n",
    "llm=AutoModelForCausalLM.from_pretrained(LLM_Model,torch_dtype=torch.float16,device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:27.186550Z",
     "iopub.status.busy": "2025-11-29T10:09:27.186065Z",
     "iopub.status.idle": "2025-11-29T10:09:27.190861Z",
     "shell.execute_reply": "2025-11-29T10:09:27.190236Z",
     "shell.execute_reply.started": "2025-11-29T10:09:27.186521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def llm_generate(prompt, max_new_tokens=256):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n",
    "\n",
    "    output = llm.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:27.192899Z",
     "iopub.status.busy": "2025-11-29T10:09:27.192657Z",
     "iopub.status.idle": "2025-11-29T10:09:27.202562Z",
     "shell.execute_reply": "2025-11-29T10:09:27.201823Z",
     "shell.execute_reply.started": "2025-11-29T10:09:27.192882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_rag(patient_case, kb_items, kb_embeddings):\n",
    "    query = patient_case[\"input_text\"]\n",
    "\n",
    "    retrieved = retrieve_from_kb(\n",
    "        model,\n",
    "        query,\n",
    "        kb_embeddings,\n",
    "        kb_items,\n",
    "        TOP_K\n",
    "    )\n",
    "\n",
    "    prompt = construct_prompt(patient_case, retrieved)\n",
    "    answer = llm_generate(prompt)\n",
    "\n",
    "    return answer, retrieved, prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:27.203651Z",
     "iopub.status.busy": "2025-11-29T10:09:27.203323Z",
     "iopub.status.idle": "2025-11-29T10:09:39.343680Z",
     "shell.execute_reply": "2025-11-29T10:09:39.342893Z",
     "shell.execute_reply.started": "2025-11-29T10:09:27.203627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\Muhammad Abu Huraira\\AppData\\Local\\Temp\\ipykernel_8740\\350318453.py:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  kb_items = load_data(\"mimic-iv-ext-direct-1.0.0\\My_dataset\\combined_rag_data.json\")\n",
      "C:\\Users\\Muhammad Abu Huraira\\AppData\\Local\\Temp\\ipykernel_8740\\350318453.py:1: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  kb_items = load_data(\"mimic-iv-ext-direct-1.0.0\\My_dataset\\combined_rag_data.json\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mimic-iv-ext-direct-1.0.0\\\\My_dataset\\\\combined_rag_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m kb_items = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmimic-iv-ext-direct-1.0.0\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mMy_dataset\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mcombined_rag_data.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m model = SentenceTransformer(MODEL_NAME)\n\u001b[32m      4\u001b[39m kb_embeddings = generate_vector_embedding(model, kb_items)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(file_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(file_name):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m         data=json.load(f)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'mimic-iv-ext-direct-1.0.0\\\\My_dataset\\\\combined_rag_data.json'"
     ]
    }
   ],
   "source": [
    "kb_items = load_data(\"mimic-iv-ext-direct-1.0.0\\My_dataset\\combined_rag_data.json\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "kb_embeddings = generate_vector_embedding(model, kb_items)\n",
    "\n",
    "patient_case = {\n",
    "    \"input_text\": \"A 60-year-old male with sudden chest pain radiating to back...\"\n",
    "}\n",
    "\n",
    "answer, retrieved, prompt = run_rag(patient_case, kb_items, kb_embeddings)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using API Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:39.347995Z",
     "iopub.status.busy": "2025-11-29T10:09:39.347310Z",
     "iopub.status.idle": "2025-11-29T10:09:52.893860Z",
     "shell.execute_reply": "2025-11-29T10:09:52.893170Z",
     "shell.execute_reply.started": "2025-11-29T10:09:39.347968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install google-generativeai python-dotenv --quiet\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Get API key\n",
    "api_key = \"APIKey\"\n",
    "\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"\"\"\n",
    "You are a medical assistant.\n",
    "First explain what it diesase could be then give all the reasons\n",
    "Explain the symptoms of a 60-year-old male with sudden chest pain radiating to the back.\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8856101,
     "sourceId": 13900478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
