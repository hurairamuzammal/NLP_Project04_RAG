{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:06:26.091822Z",
     "iopub.status.busy": "2025-11-29T10:06:26.091588Z",
     "iopub.status.idle": "2025-11-29T10:06:59.560539Z",
     "shell.execute_reply": "2025-11-29T10:06:59.559930Z",
     "shell.execute_reply.started": "2025-11-29T10:06:26.091794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 10:06:39.647040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764410799.841327      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764410799.890785      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:06:59.562477Z",
     "iopub.status.busy": "2025-11-29T10:06:59.561903Z",
     "iopub.status.idle": "2025-11-29T10:08:09.782095Z",
     "shell.execute_reply": "2025-11-29T10:08:09.781172Z",
     "shell.execute_reply.started": "2025-11-29T10:06:59.562460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate huggingface-hub sentence-transformers faiss-cpu streamlit python-dotenv --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:08:09.783574Z",
     "iopub.status.busy": "2025-11-29T10:08:09.783242Z",
     "iopub.status.idle": "2025-11-29T10:08:09.787826Z",
     "shell.execute_reply": "2025-11-29T10:08:09.787177Z",
     "shell.execute_reply.started": "2025-11-29T10:08:09.783540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# using this lightweight sentence transformer\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "TOP_K=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:08:09.788859Z",
     "iopub.status.busy": "2025-11-29T10:08:09.788596Z",
     "iopub.status.idle": "2025-11-29T10:08:09.803277Z",
     "shell.execute_reply": "2025-11-29T10:08:09.802629Z",
     "shell.execute_reply.started": "2025-11-29T10:08:09.788837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    with open(file_name,\"r\",encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "    return data\n",
    "\n",
    "def generate_vector_embedding(model, kb_items):\n",
    "    print(\"Creating Vector embeddings of the json file\")\n",
    "    texts = [f\"{item.get('id','')} : {item.get('medicalKB','')}\" for item in kb_items]\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def retrieve_from_kb(model, query_text, kb_embeddings, kb_items, k=TOP_K):\n",
    "    query_emb = model.encode(query_text, convert_to_tensor=True)\n",
    "\n",
    "    cos_scores = util.cos_sim(query_emb, kb_embeddings)[0]\n",
    "    scores = cos_scores.cpu().numpy()\n",
    "\n",
    "    k = min(k, len(scores))\n",
    "    top_idx = np.argpartition(-scores, range(k))[:k]\n",
    "    top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append((\n",
    "            kb_items[int(idx)],\n",
    "            float(scores[int(idx)])\n",
    "        ))\n",
    "\n",
    "    return results\n",
    "\n",
    "def construct_prompt(patient_case, retrieved_kb):\n",
    "    context_str = \"Medical Knowledge:\\n\"\n",
    "    for item, score in retrieved_kb:\n",
    "        context_str += f\"- [{item.get('id','')}] {item.get('medicalKB','')} (Relevance: {score:.2f})\\n\"\n",
    "\n",
    "    case_str = f\"Patient Case Details:\\n{patient_case['input_text']}\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert medical diagnostician.\n",
    "Use the provided medical knowledge to explain the patient case.\n",
    "\n",
    "{context_str}\n",
    "\n",
    "{case_str}\n",
    "\n",
    "Give reasoning and final answer.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:08:09.804349Z",
     "iopub.status.busy": "2025-11-29T10:08:09.804087Z",
     "iopub.status.idle": "2025-11-29T10:09:27.185231Z",
     "shell.execute_reply": "2025-11-29T10:09:27.184595Z",
     "shell.execute_reply.started": "2025-11-29T10:08:09.804333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6246c706b999412ab0a2866aec9f46ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c8263eb6c64df88c544238b8023c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7052a6f164c44c0aaa633994f40742d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f3f4deb4214f65bf45bf49e4d26266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18aeac204c33400dac9600e452e8255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5def62b9acc843a696abfb2d1ae74ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc1e27a317b4404a7ff46290a5ad26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591e20b3e0274c24ae92209ae42e9bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b447d56275a14f52b2e802fe2ac49142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "import torch\n",
    "LLM_Model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(LLM_Model,use_fast=False)\n",
    "llm=AutoModelForCausalLM.from_pretrained(LLM_Model,torch_dtype=torch.float16,device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:27.186550Z",
     "iopub.status.busy": "2025-11-29T10:09:27.186065Z",
     "iopub.status.idle": "2025-11-29T10:09:27.190861Z",
     "shell.execute_reply": "2025-11-29T10:09:27.190236Z",
     "shell.execute_reply.started": "2025-11-29T10:09:27.186521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def llm_generate(prompt, max_new_tokens=256):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n",
    "\n",
    "    output = llm.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:27.192899Z",
     "iopub.status.busy": "2025-11-29T10:09:27.192657Z",
     "iopub.status.idle": "2025-11-29T10:09:27.202562Z",
     "shell.execute_reply": "2025-11-29T10:09:27.201823Z",
     "shell.execute_reply.started": "2025-11-29T10:09:27.192882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_rag(patient_case, kb_items, kb_embeddings):\n",
    "    query = patient_case[\"input_text\"]\n",
    "\n",
    "    retrieved = retrieve_from_kb(\n",
    "        model,\n",
    "        query,\n",
    "        kb_embeddings,\n",
    "        kb_items,\n",
    "        TOP_K\n",
    "    )\n",
    "\n",
    "    prompt = construct_prompt(patient_case, retrieved)\n",
    "    answer = llm_generate(prompt)\n",
    "\n",
    "    return answer, retrieved, prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:27.203651Z",
     "iopub.status.busy": "2025-11-29T10:09:27.203323Z",
     "iopub.status.idle": "2025-11-29T10:09:39.343680Z",
     "shell.execute_reply": "2025-11-29T10:09:39.342893Z",
     "shell.execute_reply.started": "2025-11-29T10:09:27.203627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8b4691201f4a6fb216a94635624c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7fffcee7884b0abedc31b0aea4fc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea158d4f83443798b1893937d563736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4dc0f3cc6c4c0aab2282ab056bc765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999ebcdfc494440a8143289d35faf14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acc99f653564898b008b528f987296b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1c81714f134d5885d53b71c06d3ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bf9d2de8bd45deb61c5ac135798337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b48daf49f94975b3f9b467f2f78938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595d881e938b42ff8e9e9955a392f9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b96e51efd14baaba42fef93ad086b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vector embeddings of the json file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert medical diagnostician.\n",
      "Use the provided medical knowledge to explain the patient case.\n",
      "\n",
      "Medical Knowledge:\n",
      "- [] knowledge/Suspected Aortic Dissection/Symptoms: Intense chest or upper back pain, Sudden severe abdominal pain, Loss of consciousness, Shortness of breath, Weakness or paralysis, Weak pulse in one arm or thigh, Leg pain, Difficulty speaking or loss of vision; etc. (Relevance: 0.53)\n",
      "- [] diagnostic/Suspected Cardiomyopathy/Restrictive Cardiomyopathy: [] (Relevance: 0.51)\n",
      "- [] diagnostic/Suspected Cardiomyopathy/Arrhythmogenic Right Ventricular Cardiomyopathy: [] (Relevance: 0.47)\n",
      "- [] knowledge/Suspected Cardiomyopathy/Symptoms: Fatigue and weakness, Shortness of breath, Swelling of the legs and ankles, Arrhythmias, Chest pain; etc. (Relevance: 0.47)\n",
      "\n",
      "\n",
      "Patient Case Details:\n",
      "A 60-year-old male with sudden chest pain radiating to back...\n",
      "\n",
      "Give reasoning and final answer.\n",
      "</think>\n",
      "\n",
      "The patient is a 60-year-old male presenting with sudden chest pain that radiates to the back. This presentation aligns with the symptoms of aortic dissection, which include intense chest or upper back pain, sudden severe abdominal pain, loss of consciousness, shortness of breath, weakness or paralysis, weak pulse in one arm or thigh, leg pain, difficulty speaking, or loss of vision. The diagnostic suspicion for restrictive cardiomyopathy or arrhythmogenic right ventricular cardiomyopathy is considered, but the primary focus is on the aortic dissection due to the chest and back pain.\n"
     ]
    }
   ],
   "source": [
    "kb_items = load_data(\"/kaggle/input/medicaldataset-nlp-a04/combined_rag_data.json\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "kb_embeddings = generate_vector_embedding(model, kb_items)\n",
    "\n",
    "patient_case = {\n",
    "    \"input_text\": \"A 60-year-old male with sudden chest pain radiating to back...\"\n",
    "}\n",
    "\n",
    "answer, retrieved, prompt = run_rag(patient_case, kb_items, kb_embeddings)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using API Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T10:09:39.347995Z",
     "iopub.status.busy": "2025-11-29T10:09:39.347310Z",
     "iopub.status.idle": "2025-11-29T10:09:52.893860Z",
     "shell.execute_reply": "2025-11-29T10:09:52.893170Z",
     "shell.execute_reply.started": "2025-11-29T10:09:39.347968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mOkay, here's how I would explain the potential symptoms of a 60-year-old male presenting with sudden chest pain radiating to the back, keeping in mind this is for informational purposes and **not a diagnosis**. This individual needs immediate medical attention.\n",
      "\n",
      "\"Sir/Ma'am, I understand you're experiencing sudden chest pain that radiates to your back. This is a serious symptom and requires immediate evaluation.  Let me describe the potential causes and why we need to act quickly.\n",
      "\n",
      "**The Key Symptoms:**\n",
      "\n",
      "*   **Sudden Chest Pain:** This is the primary concern. We need to know:\n",
      "    *   **Location:**  Where in your chest is the pain the strongest? Is it central, on one side, or elsewhere?\n",
      "    *   **Character:** Is it sharp, stabbing, crushing, squeezing, burning, or a dull ache?\n",
      "    *   **Severity:** On a scale of 0 to 10, with 0 being no pain and 10 being the worst pain imaginable, how would you rate it?\n",
      "    *   **Duration:** How long has the pain been going on?\n",
      "    *   **Triggers:** What were you doing when the pain started? Did it come on suddenly or gradually? Does anything make it better or worse (e.g., breathing, lying down, sitting up, taking a deep breath)?\n",
      "*   **Radiation to the Back:** This is a *very* important detail. The pain moving from the chest to the back significantly raises suspicion for certain conditions.\n",
      "\n",
      "**Possible (and Serious) Underlying Conditions:**\n",
      "\n",
      "Because of the combination of chest pain radiating to the back, we have to consider a few possibilities, some of which are life-threatening:\n",
      "\n",
      "*   **Aortic Dissection:** This is a tear in the wall of the aorta (the main artery carrying blood from the heart).  The pain is often described as **sudden, severe, tearing, or ripping**. The radiation to the back is a classic symptom.  This is a medical emergency.\n",
      "*   **Myocardial Infarction (Heart Attack):**  While chest pain radiating down the left arm is more typical, it *can* radiate to the back, especially in certain individuals. The pain is often described as **pressure, squeezing, tightness, or crushing**. There may also be shortness of breath, sweating, nausea, or lightheadedness.\n",
      "*   **Angina:** Chest pain due to reduced blood flow to the heart. It's similar to a heart attack but less severe and often triggered by exertion.\n",
      "*   **Pulmonary Embolism (PE):** A blood clot in the lungs. This can cause sudden chest pain, especially with breathing, and potentially radiate to the back.  Shortness of breath is also a common symptom.\n",
      "*   **Other possibilities, although less likely given the radiation to the back, include:**\n",
      "    *   **Esophageal Spasm:** Pain in the esophagus (the tube connecting your mouth to your stomach)\n",
      "    *   **Pericarditis:** Inflammation of the sac surrounding the heart.\n",
      "\n",
      "**Associated Symptoms We Need to Know About:**\n",
      "\n",
      "To help the doctor determine the most likely cause, I also need to ask about other symptoms, such as:\n",
      "\n",
      "*   **Shortness of breath**\n",
      "*   **Sweating (diaphoresis)**\n",
      "*   **Nausea or vomiting**\n",
      "*   **Lightheadedness or dizziness**\n",
      "*   **Palpitations (feeling like your heart is racing or skipping beats)**\n",
      "*   **Weakness or fatigue**\n",
      "*   **Anxiety or a sense of impending doom**\n",
      "*   **Cough**\n",
      "*   **Leg pain or swelling**\n",
      "\n",
      "**Why Immediate Action is Necessary:**\n",
      "\n",
      "Aortic dissection and heart attack require immediate diagnosis and treatment to prevent serious complications, including death. A pulmonary embolism can also be life-threatening.  The faster we can determine the cause, the better the chance of a positive outcome.\n",
      "\n",
      "**What Happens Next:**\n",
      "\n",
      "I will immediately alert the doctor and we will:\n",
      "\n",
      "*   **Take your vital signs:**  Blood pressure, heart rate, respiratory rate, temperature, and oxygen saturation.\n",
      "*   **Perform an ECG/EKG:**  This will help us assess your heart's electrical activity.\n",
      "*   **Administer oxygen:** To ensure you are getting enough oxygen.\n",
      "*   **Draw blood:** For various tests, including cardiac enzymes (to check for heart damage) and other markers.\n",
      "*   **Prepare for potential further testing:**  This may include a chest X-ray, CT scan, or echocardiogram.\n",
      "\n",
      "**Important:** Please tell me *immediately* if your symptoms change or worsen at all while we are waiting for the doctor.\"\n",
      "\n",
      "**Important Disclaimer:** This is not a substitute for professional medical advice.  It is crucial that the patient be evaluated by a qualified healthcare professional as soon as possible. This information is for educational purposes only.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai python-dotenv --quiet\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Get API key\n",
    "api_key = \"APIKey\"\n",
    "\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"\"\"\n",
    "You are a medical assistant.\n",
    "Explain the symptoms of a 60-year-old male with sudden chest pain radiating to the back.\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8856101,
     "sourceId": 13900478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
